#!/bin/bash
#-- NOT A REAL SHELL SCRIPT!   This is a cut'n'paste scriptlet!
#   Be sure to read & understand what you're cutting & pasting!
#------------------------------------------------------------------------------
# name:    OKD (OpenShift Origin) Notes (miscNotes)
# author:  awmyhr@gmail.com
# revised: 20180822-164710
# created: 2018-08-10
#------------------------------------------------------------------------------
#-- Minishift stuff
#------------------------------------------------------------------------------
# OpenShift server start/stop.
minishift [start|stop]
# Get minishift IP address
minishift ip
# Get minishift env (PATH) settings
minishift oc-env
# The server is accessible via web console at:
#     https://$(minishift ip):8443
#------------------------------------------------------------------------------
#-- "Quick" All-in-one binary download install
#------------------------------------------------------------------------------
RELEASE='v3.10.0'
BUILD='dd10d17'
PLATFORM='linux-64bit'
# (as root)
wget -O /var/tmp/open-shift-server.tgz "https://github.com/openshift/origin/releases/download/${RELEASE}/openshift-origin-server-${RELEASE}-${BUILD}-${PLATFORM}.tar.gz"
cd /opt \
    && tar zxf /var/tmp/open-shift-server.tgz \
    && ln -s "openshift-origin-server-${RELEASE}-${BUILD}-${PLATFORM}" openshift \
    && export PATH=/opt/openshift:"${PATH}" && cd - || return
openshift start >var/log/openshift.log 2>&1 &
# may or may not need to set these
export KUBECONFIG="${HOME}"/openshift.local.config/master/admin.kubeconfig
export CURL_CA_BUNDLE="${HOME}"/openshift.local.config/master/ca.crt
chmod +r "${HOME}"/openshift.local.config/master/admin.kubeconfig

#------------------------------------------------------------------------------
#-- "Full" Ansible-based install prep
#   See also Ansible playbook 'openShiftPrep.yml'
#   This smooths over some common issues I've
#   seen with running the Ansible playbooks.
#------------------------------------------------------------------------------
#-- Filesystems
#-- (maybe) make a docker-vg (this may override /var/lib/docker)
#   /var (and sub-fs) itself should have total of 5GB+ before below
#   /tmp and /usr/local/bin should have 1GB+ free
#-- An additional minimum 15 GB unallocated space per system running containers
#   for Dockerâ€™s storage back end; see Configuring Docker Storage. Additional
#   space might be required, depending on the size and number of containers that
#   run on the node.
mkdir /var/lib/docker /var/lib/origin
chown root:root /var/lib/docker /var/lib/origin
chmod 0755 /var/lib/docker /var/lib/origin
lvcreate --yes -L 30G -n var.lib.docker vg01 && mkfs.xfs /dev/mapper/vg01-var.lib.docker
lvcreate --yes -L  5G -n var.lib.origin vg01 && mkfs.xfs /dev/mapper/vg01-var.lib.origin
cat >>/etc/fstab <<EOF
/dev/mapper/vg01-var.lib.docker /var/lib/docker   xfs     defaults,relatime       0 0
/dev/mapper/vg01-var.lib.origin /var/lib/origin   xfs     defaults,relatime       0 0
EOF
mount /var/lib/docker
mount /var/lib/origin

#-- On NFS node (if needed)
mkdir /exports
chown root:root /exports
chmod 0755 /exports
lvcreate --yes -L 30G -n exports vg01 && mkfs.xfs /dev/mapper/vg01-exports
cat >>/etc/fstab <<EOF
/dev/mapper/vg01-exports        /exports          xfs     defaults,relatime       0 0
EOF
mount /exports

groupadd -g 980 docker
#------------------------------------------------------------------------------
#-- For RHEL -- additional installs before playbooks run
yum install -y git iptables-services pyOpenSSL python-cryptography
yum-config-manager -q --enable rhel-7-server-ansible-2-rpms >/dev/null
yum install -y ansible
yum-config-manager -q --enable rhel-7-server-extras-rpms >/dev/null
yum install -y atomic cockpit-docker docker python-crypto
#-- For CentOS
yum install -y epel-release
yum install -y ansible git docker python-cryptography python-crypto pyOpenSSL
#------------------------------------------------------------------------------
#-- End Install prep
#------------------------------------------------------------------------------
#-- Docker should set this on start
# sysctl -w net.ipv4.ip_forward=1
#-- From what I can tell these are just annoying to see, not impactful
# sysctl -w net.bridge.bridge-nf-call-iptables=1
# sysctl -w net.bridge.bridge-nf-call-ip6tables=1

#------------------------------------------------------------------------------
#-- Ansible based installer for okd
OSADIR="${TMPDIR:-/tmp}"/osa
git clone https://github.com/openshift/openshift-ansible.git "${OSADIR}"
cd "${OSADIR}" && git checkout --track origin/release-3.10 && cd - || return
cp "${OSADIR}"/inventory/hosts.example okd-hosts

#-- Customize okd-hosts
#   Here are the vars I've worked with
# [OSEv3:vars]
# debug_level=2
# ansible_user=root
# os_firewall_use_firewalld=True
# openshift_deployment_type=origin
# openshift_release="3.10"
# openshift_portal_net=172.30.0.0/16
# osm_cluster_network_cidr=10.128.0.0/14
# #-- This sets up basic htpasswd authentication
# openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider',}]
# #-- Some environments will need to set insecure registries
# openshift_docker_insecure_registries=172.17.0.0/16,172.30.0.0/16,quay.io,docker.io,registry.access.redhat.com
# #-- Setup NFS-based persistant storage for the docker registry
# #   Keep in mind this is an unsupported config, and must be flagged thus
# openshift_enable_unsupported_configurations=True
# openshift_hosted_registry_storage_kind=nfs
# openshift_hosted_registry_storage_access_modes=['ReadWriteMany']
# openshift_hosted_registry_storage_nfs_directory=/exports
# openshift_hosted_registry_storage_nfs_options='*(rw,root_squash)'
# openshift_hosted_registry_storage_volume_name=registry
# openshift_hosted_registry_storage_volume_size=5Gi

#-- Now run the playbooks
ansible-playbook -i okd-hosts "${OSADIR}"/playbooks/prerequisites.yml
ansible-playbook -i okd-hosts "${OSADIR}"/playbooks/deploy_cluster.yml
#-- I have always had to run the deploy_cluster playbook a second time
#   after rebooting all the nodes.
#   However, before this:
# TASK [openshift_web_console : Verify that the console is running] *****************************
#   I've needed to run this:
# sysctl -w net.ipv4.ip_forward=1
#   But this doesn't work the first time around

#-- or run against localhost for a single, all-in-one setup
# ansible-playbook -i "${OSADIR}"/inventory/hosts.localhost "${OSADIR}"/playbooks/prerequisites.yml
# ansible-playbook -i "${OSADIR}"/inventory/hosts.localhost "${OSADIR}"/playbooks/deploy_cluster.yml

#------------------------------------------------------------------------------
#-- Post install quick cheks
#------------------------------------------------------------------------------
#-- Check nodes are running
oc get nodes
#-- list all currently running pods
oc get pods --all-namespaces -o wide
# get info on 'everything' in project
oc get all
#-- Get status
oc status
#-- Make sure we have NTP
timedatectl
#-- Get current entropy, should be over 1000, advise to alert if under 800
cat /proc/sys/kernel/random/entropy_avail
#-- Check default storage class
oc get storageclass
# log into a pod
oc rsh "${PODNAME}"

#-- login as system:admin (aka superuser) while os user is root
oc login -u system:admin
#------------------------------------------------------------------------------
#-- Registry schtuff
#------------------------------------------------------------------------------
oc logs dc/docker-registry
oc describe svc/docker-registry
oc describe dc/docker-registry
oc describe pod "$(oc get pods --no-headers | grep docker-registry | cut -f1 -d' ')"
docker ps --filter=name=registry_docker-registry.*_default_
docker login "$(docker ps -q --filter=name=registry_docker-registry.*_default_)"

docker login -u openshift -p "$(oc whoami -t)" "${DR_IP}:${DR_PORT}"

#-- add registry permissions
oc policy add-role-to-user registry-viewer "${USER}"
oc policy add-role-to-user registry-editor "${USER}"

#-- create pv/pvc files for docker-registry, then add them
oc create -f docker-registry-nfs-pv.yml
oc create -f docker-registry-nfs-pvc.yml
#------------------------------------------------------------------------------
#--  Sample application
#------------------------------------------------------------------------------
oc new-project test-project
# Create a Node.js example app:
oc new-app https://github.com/openshift/nodejs-ex -l name=myapp
# Track the build log until the app is built and deployed:
oc logs -f bc/nodejs-ex
# Expose a route to the service:
oc expose svc/nodejs-ex
# If running Minishift, access the application:
minishift openshift service nodejs-ex --in-browser
# scale it
oc scale --replicas=2 dc nodejs-ex
# get service/dc/bc info (these can be 'resource name' or 'resource/name')
oc get svc nodejs-ex
oc get dc  nodejs-ex
oc get bc  nodejs-ex
# more detailed info
oc describe svc nodejs-ex
# delete the project
oc delete project test-project

#------------------------------------------------------------------------------
#-- NFS stuff
#------------------------------------------------------------------------------
#-- Enable writing from pod to remote NFS server
setsebool -P virt_sandbox_use_nfs on
setsebool -P virt_use_nfs on

#------------------------------------------------------------------------------
#-- GlusterFS stuff
#------------------------------------------------------------------------------
yum install glusterfs-fuse
#-- Enable writing from pod to remote GlusterFS server
setsebool -P virt_sandbox_use_fusefs on
setsebool -P virt_use_fusefs on

